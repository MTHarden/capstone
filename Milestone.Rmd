---
title: "Milestone"
author: "Mitch Harden"
date: "03/27/2015"
output: pdf_document
---

The goal of this report is briefly explain the major features of the data and to concisely summarize plans for creating a prediction algorhythm and shiny app. 


Load Libraries

```{r}
library(NLP)
library(RColorBrewer)
library(stringi)
library(tm)
library(wordcloud)
```

Read the data

```{r}
#Load data
blogs = readLines("en_US.blogs.txt")
news = readLines("en_US.news.txt")
twitter = readLines("en_US.twitter.txt")
```

Data Exploration
----------------

A quick look at the scope of this data reveals that it is too large to work with directly. A sample from each of the three data files is generated to use during this exploratory analysis.

Determine the size of Blogs data file
```{r, eval=FALSE }
length(blogs)
[1] 899288
object.size(blogs)
260564320 bytes
```

Determine the size of News data file
```{r, eval=FALSE }
length(news)
[1] 1010242
object.size(news)
20111392 bytes
```

Determine the size of Twitter data file
```{r, eval=FALSE }
length(tweets)
[1] 2360148
object.size(tweets)
316037344 bytes
```

Create Samples of all three data files
```{r}
set.seed(12345) # Just like my luggage
blogSample = sample(blogs, 1000)
newsSample = sample(news, 1000)
twitterSample = sample(twitter, 1000)
```

Now that the data files are more manageable they can be manipulated to explore word frequency
```{r}
## Blogs advanced
## Join the elements of a character vector into one string
blogString <- stri_flatten(blogSample, collapse =" ")
## Extracts all words from the string
blogWords <- unlist(stri_extract_all_words(blogString, locale = "en"))
## Transform strings to lower case to identify unique words correctly
blogWords <- stri_trans_tolower(blogWords, locale = "en")
## Total number of words in blogs sample
bwordsNum <- length(blogWords)
bwordsNum
## Unique number of words in blogs sample
ubwordsNum <- length(unique(blogWords))
ubwordsNum

## News advanced
## Join the elements of a character vector into one string
newsString <- stri_flatten(newsSample, collapse =" ")
## Extracts all words from the string
newsWords <- unlist(stri_extract_all_words(newsString, locale = "en"))
## Transform strings to lower case to identify unique words correctly
newsWords <- stri_trans_tolower(newsWords, locale = "en")
## Total number of words in news sample
nwordsNum <- length(newsWords)
nwordsNum
## Unique number of words in news sample
unwordsNum <- length(unique(newsWords))
unwordsNum

## Twitter advanced
## Join the elements of a character vector into one string
twitterString <- stri_flatten(twitterSample, collapse =" ")
## Extracts all words from the string
twitterWords <- unlist(stri_extract_all_words(twitterString, locale = "en"))
## Transform strings to lower case to identify unique words correctly
twitterWords <- stri_trans_tolower(twitterWords, locale = "en")
## Total number of words in tweet sample
twordsNum <- length(twitterWords)
twordsNum
## Unique number of words in tweet sample
utwordsNum <- length(unique(twitterWords))
utwordsNum

## Corpus
blogCorpus = Corpus(VectorSource(blogWords))
newsCorpus = Corpus(VectorSource(newsWords))
twitterCorpus = Corpus(VectorSource(twitterWords))
```

Visual Representation of Text Data
----------------------------------

A wordcloud is a quick and easy way to visualize the importance and frequency of words.

**BLOGS WORD CLOUD**

```{r blogCorpus, echo=TRUE, warning=FALSE, message=FALSE, fig.align='left'}
wordcloud(blogCorpus, scale=c(3,0.5),
          min.freq=5, max.words=150, random.order=TRUE,
          rot.per=0.5, use.r.layout=FALSE,
          colors=brewer.pal(8, "Dark2"))
```

**NEWS WORD CLOUD**

```{r newsCorpus, echo=TRUE, warning=FALSE, message=FALSE, fig.align='left'}
wordcloud(newsCorpus, scale=c(3,0.5),
          min.freq=5, max.words=150, random.order=TRUE,
          rot.per=0.5, use.r.layout=FALSE,
          colors=brewer.pal(8, "Dark2"))
```

**TWITTER WORD CLOUD**

```{r twitterCorpus, echo=TRUE, warning=FALSE, message=FALSE, fig.align='left'}
wordcloud(twitterCorpus, scale=c(3,0.5),
          min.freq=5, max.words=150, random.order=TRUE,
          rot.per=0.5, use.r.layout=FALSE,
          colors=brewer.pal(8, "Dark2"))
```

Conclusions and Next Steps
-----------
Twitter has fewer unique words than blogs. Next I will have to learn how to do the N-gram thing. Split the data up so I can start creating, refining and testing prediction models, and create a shiny app for presentation.
